## 网络并发问题 ##

### <b>如何支持10K， 100K， 1000K并发请求？</b> ###
- 物理资源：
    1. 同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。

- 软件瓶颈：
    1. 每个请求都分配一个进程或者线程。请求数增加到 10000 个请求时，进程或线程的调度，上下文切换，占用的内存，都会成为瓶颈。
    2. 注意： 想要使用 SO_REUSEPORT 选项，需要用 Linux 3.9 以上的版本才可以。

- epoll配合线程池，再加上 CPU、内存和网络接口的性能和容量提升。大部分情况下，10K, 100K, 100K 很自然就可以达到。

### <b>如何支持1000K并发请求？</b> ###
- 物理资源：
    1. 内存资源：10000K个请求需要大量的系统资源。假设每个请求需要 16KB 内存的话，那么总共就需要大约15GB内存，10M则需要更大。
    2. 带宽资源：
        - 假设只有20%活跃连接，即使每个连接只需要 1KB/s 的吞吐量，总共也需要 1.6 Gb/s 的吞吐量。
        - 千兆网卡满足不了这吞吐量，需要配置万兆网卡或者基于多网卡Bonding承载更大的吞吐量。

- 软件瓶颈：
    1. 文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）等等
    2. 大量中断请求处理，也会带来非常高的处理成本

 - 解决方案：
    1. 多队列网卡、中断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个CPU核上）
    2. 网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化
    3. 在 epoll 的非阻塞 I/O 模型上，从应用程序到 Linux 内核、再到 CPU、内存和网络等各个层次的深度优化，借助硬件，来卸载那些原来通过软件处理的大量功能

### <b>如何支持10M并发请求？</b> ###
> 本质问题：Linux 内核协议栈做了太多太繁重的工作。从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了

- 跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，DPDK 和 XDP。
    1. DPDK
        - 跳过协议栈，用户态进程轮询网络请求。
        - 大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。
    2. XDP (Linux 4.8 以上版本)
        - 允许网络包，在进入内核协议栈之前，就进行处理。
        - 基于 Linux 内核的 eBPF 机制实现
        - 不提供缓存队列。基于XDP的应用程序通常是专用的网络应用，常见的有 IDS（入侵检测系统）、DDoS 防御、 cilium 容器网络插件等。
- 小结：
    1. PDK 是目前最主流的高性能网络方案，这需要能支持DPDK的网卡配合使用。
    2. 调整系统架构，把请求分发到多台服务器中并行处理，才是更简单、扩展性更好的方案。
